#!/usr/bin/env python3
"""
Filename: lib_Unigram.py (to be imported as a module)
Author: Chng Eng Siong
Date: 31 July 2021
Last edited: 1st Aug 2021 (CES), 11:07pm

# This library supports the reading a unigram count file generated by ngram-count
# it assumes 2 fields, 1 left field == string, right field == count
# we will not assume anything else, and the string can be non-english words.
# we will remove ALL non-english entries, and resort.
"""
import logging
import os, sys, io
from   libWord import C_WordList, C_OneWord
import argparse
import pandas as pd
# must install pandas, using bash cmd line:
# sudo apt-get install python3-pandas
# you can read about pandas here: 
# https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python

from nltk.corpus import words
# we need this to check if the token is a english word
# to speed things up, we define a set on the words
# see: https://stackoverflow.com/questions/57842654/is-there-any-faster-way-to-check-from-a-words-list-with-nltk-with-python

logging.basicConfig(
    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s [%(filename)s:%(lineno)d] %(message)s',
    datefmt='%H:%M:%S',
    level=logging.INFO)
log = logging.getLogger("{}".format(os.path.basename(sys.argv[0])))


def wordIsRomanChars(w):
    return w[0].upper() and all([ord(c) <128 or (ord(c) >= 65313 and ord(c) <= 65339) or (ord(c) >= 65345 and ord(c) <= 65371) for c in w])


#Example to run the code
"""
python3 run_createhotWordLexiconUnigram.py --unigram_countFile ./TestData_Clean/unigram.count --topNunigram 1000 --hotwordRawList \
  ./TestData_Clean/hotwordRawList.txt  --opHotDecoderLexicon ./TestData_Op/hotwordDecoderLex.txt \
  --opHotDecoderUnigram ./TestData_Op/hotwordDecoderUnigram\
  --fixHotWord_position 300
"""

def real_main():        
    log.info("{}".format("reading given unigram count to create English lexicon for hotwords..."))
    parse = argparse.ArgumentParser()
    parse.add_argument('--unigram_countFile',    required=True,  help="unigram count of Master Kaldi ASR")
    parse.add_argument('--topNunigram',      type=int, default=5000, help="find topN unigrams (english words) will be retained")
    parse.add_argument('--hotwordRawList',   required=True,  help="hotword raw list file ")
    parse.add_argument('--opHotDecoderLexicon', required=True,  help="hotword decoder lexicon")
    parse.add_argument('--opHotDecoderUnigram', required=True,  help="hotword decoder unigramcount")
    parse.add_argument('--fixHotWord_position', type=int, default=300, help="fixing hotword into sorted unigram count at position xxx")
    
    
    args = parse.parse_args()

    # Lets read the hot word first
    listWord = C_WordList()
    listWord.read_WordList( args.hotwordRawList, True)
    # we must pass it a flag to tell HIM if of if not hotWord

    # lets prepare to write the hotword decoder unigram count!!!
    opfile_HotDecoderUnigram = open( args.opHotDecoderUnigram,'w')

    # sanity check, we will not put hotword behind topNunigram
    if (args.fixHotWord_position > args.topNunigram):
        args.fixHotWord_position  = args.topNunigram

    # we will use pandas, and assume that the unigram count has 2 fields
    # The first row must NOT be ignored, hence header = none
    # see how to use pandas in: https://re-thought.com/pandas-value_counts/
    df = pd.read_csv(args.unigram_countFile, header=None, encoding='utf8', dtype={'token':'str', 'count':'int'}, sep='\t')
    # BUT pandas require 1st row to have the field ID
    # we can replocate it by the following, BUT we must save the original first!
    df.columns = ['token','count']
    sorted_df = df.sort_values('count',ascending=False)
    print('num of elements read in ',args.unigram_countFile,' = ', len(df))

    # we will save those unique english-only  words!!!
    numFound=0
    setWords =set(words.words()) # if we dont use set, its very slow!!!
    list_englishWordsUnigram = set()
    for tok,count in zip(sorted_df['token'].values, sorted_df['count'].values):
        if wordIsRomanChars(str(tok)) == 1 and numFound< args.topNunigram and (tok in setWords):
            # we ONLY keep english words with count > countThreshold
            opfile_HotDecoderUnigram.write("{0}\t{1}\n".format(tok,count))
            list_englishWordsUnigram.add(tok)
            numFound=numFound+1
            if (numFound == args.fixHotWord_position):
                foundCountThreshold = count
            if (numFound >= args.topNunigram):
                break

    print('written ',numFound,' entries in sorted_unigram')
    for oneWordStr in  listWord.listWordStr:
        oneWord = listWord.dictWStrToCWord[oneWordStr]
        countPron = 0
        for pronStr in oneWord.wordArrayPron:        
            if countPron == 0:
                opfile_HotDecoderUnigram.write("{0}\t{1}\n".format(oneWord.wordLabel , foundCountThreshold))
                countPron=countPron+1
            else:
                opfile_HotDecoderUnigram.write("{0}#{2} {1}\n".format(oneWord.wordLabel , foundCountThreshold, countPron))
                countPron=countPron+1
        numFound=numFound+countPron        

    print('written ',numFound,' entries in hotwordList')

    listOfWordToAdd = ['<s>','</s>','<unk>','<noise>','<v-noise>']
    for oneWordStr in  listOfWordToAdd:
        numFound=numFound+1
        opfile_HotDecoderUnigram.write("{0}\t{1}\n".format(oneWordStr , foundCountThreshold))

    opfile_HotDecoderUnigram.close()
    
    # saving the hotword decoder lexicon
    # it is the hotwordlist entries AND the found topN unigram entires

    listWord.add_WordList( sorted(list_englishWordsUnigram), False)  #MUST set second entry to False it is NOT a hotword
    listWord.write_WordLexicon(args.opHotDecoderLexicon)
    


def main():
    real_main()
    
if __name__ == "__main__":
    main()
